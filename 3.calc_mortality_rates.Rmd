---
title: "Calculate Mortality Rates"
author: "Aarsh"
date: '2022-10-06'
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

## Global parameters and libraries
```{r lib_glob_parameters}

# libraries
library(readr)
library(dplyr)
library(stringr)
library(magrittr)
library(ggplot2)
library(readr)
library(tidytext)
library(tidyr)
library(tidyverse)
library(sf)
library(usethis)
library(devtools)
library(readxl)


# load and document (for automatic rendering of the roxygen comments into a man file) to keep things updated
devtools::load_all()
devtools::document()

# custom operators
`%notin%` <- Negate(`%in%`)

# global parameters 
gbd_year <- 2019

# global average PM2.5 value (taken from the latest AQLI color dataset that corresponds to the June 2022 AQLI Annual report)
global_avg_pm2.5 <- 27.5

```


## Merge Relative Risks and Mortality Rates

```{r mergeRelativeRisksAndMortalityRates}

#> Read in the cleaned GBD mortality rates file (note that this does not contain the "All causes" data, that is separately downloaded below)
cleaned_gbd_mortality_rates <- read_csv("./data/intermediate/cleaned_gbd_mortality_rates.csv")

#> Read in the cleaned relative risks file
cleaned_relative_risks <- read_csv("./data/intermediate/cleaned_relative_risks.csv")

#> Read in "All causes" cleaned GBD mortality rates data
cleaned_gbd_mortality_rates_all_causes_only <- read_csv("./data/intermediate/cleaned_gbd_mortality_rates_all_causes_only.csv")

#> join the cleaned mortality and relative risks datasets
cleaned_joined_mort_rr_data <- cleaned_gbd_mortality_rates %>%
  left_join(cleaned_relative_risks, by = c("cause", "age_interval"))

#> dropping redundant columns and renaming certain columns after dropping the redundancies, then reordering the columns. Note that, it is possible that some of the function names for dplyr and plyr might clash. So, use the package prefix, before the function name. For example, to rename a column, use: dplyr::rename(), instead of just rename()
cleaned_joined_mort_rr_data <- cleaned_joined_mort_rr_data %>%
 dplyr::select(-c(age_interval_ll.y, age_interval_ul.y, cause_id.y)) %>%
  dplyr::rename(age_interval_ll = age_interval_ll.x, 
         age_interval_ul = age_interval_ul.x, 
         cause_id = cause_id.x) %>%
  dplyr::arrange(cause, age_interval)

#> converting the above dataset back into long format, such that "pm_level" and "relative risk" are columns in the new dataset and sort the dataset by cause, pm_level, age_interval
cleaned_joined_mort_rr_data_long <- cleaned_joined_mort_rr_data %>%
  pivot_longer(cols = relative_risk_pm0:relative_risk_pm90, names_to = c("pm_level"), names_pattern = "(\\d+)", values_to = "relative_risk") %>%
  arrange(cause, age_interval, pm_level)

#> For all age groups less than 25 years of age, relative risks information is not availbale. For these, assume that relative risks = 1. Also replace any missing relative risks information with 1. Below code, replaces all those rows in the "relative_risk" column, where age_interval_ul < 25, with 1. Also, if relative risks data is missing, fill it in with relative risks = 1. 

cleaned_joined_mort_rr_data_long <- cleaned_joined_mort_rr_data_long %>%
  mutate(relative_risk = ifelse(age_interval_ul < 25, 1, relative_risk), 
         relative_risk = ifelse(is.na(relative_risk) == TRUE, 1, relative_risk))

#> coercing certain numeric columns into class "numeric"
cleaned_joined_mort_rr_data_long$pm_level <- as.numeric(cleaned_joined_mort_rr_data_long$pm_level)

#> Find the pm_level in the "cleaned_joined_mort_rr_data_long" dataset that is closest to "global_average_pm2.5" that is set up top in "lib_glob_parameters" chunk.

#> pm2.5 buckets, one of which will contain the global_avg_pm2.5. This bucket will be the one that is closest to the global average PM2.5 value that is set up top. In old STATA scripts, you will find that this process is carried out by a "rounding process". But, that has to be adjusted every year the dataset changes. What I have done below is agnostic to any data changes.

# figure out the unique PM2.5 values in the data and sort them in ascending order
unique_list_of_pm2.5_val_in_data <- sort(unique(cleaned_joined_mort_rr_data_long$pm_level))

# calculate how far the global average pm2.5 value is from each of the values in the above list of unique pm2.5 values
distance_from_global_avg_pm2.5 <- abs(unique_list_of_pm2.5_val_in_data - global_avg_pm2.5)

# *New assumption in here*: Which pm_level value in our current dataset is the closest to the "global_average_pm2.5"? If there are 2 such values, choose the one with a lower pollution number, so that our estimate is a conservation one (for now)
potential_pm2.5_buckets_indices <- which(distance_from_global_avg_pm2.5 == min(distance_from_global_avg_pm2.5))

# if there are more than one potential buckets in which the global_average_pm2.5 can land, this conditional statement below chooses the bucket with a lower pm2.5 level. This is a conservative step that we take for now and will reevaluate its implications.
if(length(potential_pm2.5_buckets_indices) < 2){
  global_avg_pm2.5_rounded <- unique_list_of_pm2.5_val_in_data[potential_pm2.5_buckets_indices]
} else {
  global_avg_pm2.5_rounded <- min(unique_list_of_pm2.5_val_in_data[potential_pm2.5_buckets_indices])
}

#> create a new temp columm that will be used to create yet another "rr_normalizer" column which will be used to create yet another "adjusted_mortality_rates" column. After generating the "rr_normalizer" column, the "temp" column will be dropped as it would have served its purpose by then. The "temp" column in the step below takes in the relative risk number of those rows where pm_level = "global_avg_pm2.5_rounded" number. In other words, it takes on those relative risk numbers that correspond to the current global average pm2.5 concentration level.  

# create a new "temp" column
cleaned_joined_mort_rr_data_long <- cleaned_joined_mort_rr_data_long %>%
  mutate(temp = ifelse(pm_level == global_avg_pm2.5_rounded, relative_risk, NA))

# group by cause, and age_interval and each row of each of these groups, gets the relative risk number that is equal to mean of "temp" column for that group. Capture this new information in a new column called "rr_normalizer".
cleaned_joined_mort_rr_data_long <- cleaned_joined_mort_rr_data_long %>%
  group_by(cause, age_interval) %>%
  mutate(rr_normalizer = mean(temp, na.rm = TRUE)) %>%
  ungroup()

# drop the temp column
cleaned_joined_mort_rr_data_long <- cleaned_joined_mort_rr_data_long %>%
  select(-temp)

# add a new column called "adjusted mortality rate", which adjusts the mortality rate for a given age_cat, cause group, by their RR in relation to the RR at the rounded Global Average PM2.5. Here the assumption is that in the absence of the risk factor, age specific death rates would be proportionally lower. This dataset corresponds to the "file1" dataset in the STATA script. This is what "PM2.5 specific mortality rates" would be if PM2.5 = X. This helps us calcuate mortality rates for any given counterfactual PM2.5 value "X".

cleaned_joined_mort_rr_data_long <- cleaned_joined_mort_rr_data_long %>%
  mutate(adjusted_mortality_rate = (mortality_rate * relative_risk)/rr_normalizer)

#>---------------------------------------------------------------------------------------------->#



#>---------------- Prep "all cause" mortality rates (loaded as a separate file up top) for "actual life table computation", adjusted to reflect higher (or lower) mortality rates at PM2.5 concentrations that are higher (or lower) than the global average.------------------------------------------------->#

# create a m_diff column, that takes the difference between "actual" and "adjusted" mortality rates
cleaned_joined_mort_rr_data_long <- cleaned_joined_mort_rr_data_long %>%
  mutate(m_diff = adjusted_mortality_rate - mortality_rate)

# * (New Assumption): summarise "cleaned_joined_mort_rr_data_long" dataset by summing up "m_diff", grouped by age_cat, pm_level and then sort by "pm_level" and "age_cat". Note that this m_diff_sum (which is calculated using the adjusted mortality rates concerning the 6 causes of deaths) will be used to adjust all cause mortality rates later on in the process. It should be noted that the "m_diff_sum" that we will add to the "all cause mortality" later on in the process, is an adjustment based on the 6 disease channels in question.

cleaned_joined_mort_rr_data_long_summary <- cleaned_joined_mort_rr_data_long %>%
  group_by(age_interval, pm_level) %>%
  summarise(m_diff_sum = sum(m_diff, na.rm = TRUE)) %>%
  ungroup() %>%
  arrange(pm_level, age_interval) 
  
# (* New Assumption) merging the summary dataset generated in the above step with "cleaned_gbd_mortality_rates_all_causes" dataset, using "age_interval" as the linking key. Then rename the "mortality_rate" column to "actual_mr". Note that the "all_causes" dataset does not have a "pm_level" column. So, each age_category in the joined dataset, has an associated set of 21 pm_levels, but for all of those the mortality_rate remains the same (that is an assumption that we make). We then adjust these mortality rates, by adding in the "m_diff_sum" column to the "actual_mr" column (which is the new name of the "mortality_rate" column), the output of which is assigned to the column named "nMx".

cleaned_joined_mort_rr_data_long_summary <- cleaned_joined_mort_rr_data_long_summary %>%
  left_join(cleaned_gbd_mortality_rates_all_causes_only, by = "age_interval") %>%
  arrange(age_interval, pm_level) %>%
  rename(actual_mr = mortality_rate)

# add a new nMx column, which is created by adding the "m_diff_sum" adjustment to the all cause mortality rates. But, note that "m_diff_sum" was calculated from only 6 PM2.5 specific disease channels. This is what "all cause mortality" rates would be if PM2.5 = X (where "X" is a counterfactual concentration)
cleaned_joined_mort_rr_data_long_summary <- cleaned_joined_mort_rr_data_long_summary %>%
  mutate(nMx = actual_mr + m_diff_sum)

# replace nMx with nMx/100000 (this column represents the "Mortality rate (deaths per person-year), adjusted"): This dataset corresponds to the "file2" dataset in Ken's STATA script. nMx is the mortality incidence rate for age interval between ages x and x + n, expressed in the units of deaths per person-year
cleaned_joined_mort_rr_data_long_summary <- cleaned_joined_mort_rr_data_long_summary %>%
  mutate(nMx = nMx/100000)



#>----------------------------------------------------------------------------------------------------------->#


#> Prepare age-specific mortalities attributed to PM2.5 (for cause-deleted)------------------------------------------>#

# Note that "cleaned_joined_mort_rr_data_long" corresponds to the "file1" tempfile in the STATA scripts. Adding 2 new columns called paf (Population Attributable Fraction) and pm_mortal_rate
cleaned_joined_mort_rr_data_long <- cleaned_joined_mort_rr_data_long %>%
  mutate(paf = 1 - (1/relative_risk), 
         pm_mortality_rate = paf * adjusted_mortality_rate)

# summary for cause-deleted life table (cdlt): This is the sum of total number of deaths across all 6 causes of death (corresponds to collapse statement that we see in part "f" of the STATA script).
cleaned_joined_mort_rr_data_long_summary_cdlt <- cleaned_joined_mort_rr_data_long %>%
  group_by(age_interval, age_interval_ll, age_interval_ul, age_gap, pm_level) %>%
  summarise(pm_mortality_rate = sum(pm_mortality_rate, na.rm = TRUE)) %>%
  ungroup()

# rename pm_mortality_rate to pm_nMx and then converting pm_nMx into a rate by dividing by 100000. The resulting dataset corresponds to "file 3" in the STATA script
cleaned_joined_mort_rr_data_long_summary_cdlt <- cleaned_joined_mort_rr_data_long_summary_cdlt %>%
  rename(pm_nMx = pm_mortality_rate) %>%
  mutate(pm_nMx = pm_nMx/100000)


#>--------------------------------------------------------------------------------------------------------------------------->#

```

