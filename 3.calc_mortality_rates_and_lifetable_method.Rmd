---
title: "Calculate Mortality Rates"
author: "Aarsh"
date: '2022-10-06'
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

## Global parameters and libraries
```{r lib_glob_parameters}

# libraries
library(readr)
library(dplyr)
library(stringr)
library(magrittr)
library(ggplot2)
library(readr)
library(tidytext)
library(tidyr)
library(tidyverse)
library(sf)
library(usethis)
library(devtools)
library(readxl)


# load and document (for automatic rendering of the roxygen comments into a man file) to keep things updated
devtools::load_all()
devtools::document()

# custom operators
`%notin%` <- Negate(`%in%`)

# global parameters 
gbd_year <- 2019

# global average PM2.5 value (taken from the latest AQLI color dataset that corresponds to the June 2022 AQLI Annual report)
global_avg_pm2.5 <- 27.5

```


## Merge Relative Risks and Mortality Rates

```{r mergeRelativeRisksAndMortalityRates}

#> Read in the cleaned GBD mortality rates file (note that this does not contain the "All causes" data, that is separately downloaded below)
cleaned_gbd_mortality_rates <- read_csv("./data/intermediate/cleaned_gbd_mortality_rates.csv")

#> Read in the cleaned relative risks file
cleaned_relative_risks <- read_csv("./data/intermediate/cleaned_relative_risks.csv")

#> Read in "All causes" cleaned GBD mortality rates data
cleaned_gbd_mortality_rates_all_causes_only <- read_csv("./data/intermediate/cleaned_gbd_mortality_rates_all_causes_only.csv")

#> join the cleaned mortality and relative risks datasets
cleaned_joined_mort_rr_data <- cleaned_gbd_mortality_rates %>%
  left_join(cleaned_relative_risks, by = c("cause", "age_interval", "age_interval_ll"))

#> dropping redundant columns and renaming certain columns after dropping the redundancies, then reordering the columns. Note that, it is possible that some of the function names for dplyr and plyr might clash. So, use the package prefix, before the function name. For example, to rename a column, use: dplyr::rename(), instead of just rename()
cleaned_joined_mort_rr_data <- cleaned_joined_mort_rr_data %>%
 dplyr::select(-c(age_interval_ul.y, cause_id.y)) %>%
  dplyr::rename(age_interval_ul = age_interval_ul.x, 
         cause_id = cause_id.x) %>%
  dplyr::arrange(cause, age_interval_ll)

#> converting the above dataset back into long format, such that "pm_level" and "relative risk" are columns in the new dataset and sort the dataset by cause, pm_level, age_interval
cleaned_joined_mort_rr_data_long <- cleaned_joined_mort_rr_data %>%
  pivot_longer(cols = relative_risk_pm0:relative_risk_pm90, names_to = c("pm_level"), names_pattern = "(\\d+)", values_to = "relative_risk") %>%
  arrange(cause, age_interval_ll, pm_level)

#> For all age groups less than 25 years of age, relative risks information is not availbale. For these, assume that relative risks = 1. Also replace any missing relative risks information with 1. Below code, replaces all those rows in the "relative_risk" column, where age_interval_ul < 25, with 1. Also, if relative risks data is missing, fill it in with relative risks = 1. 

cleaned_joined_mort_rr_data_long <- cleaned_joined_mort_rr_data_long %>%
  mutate(relative_risk = ifelse(age_interval_ul < 25, 1, relative_risk), 
         relative_risk = ifelse(is.na(relative_risk) == TRUE, 1, relative_risk))

#> coercing certain numeric columns into class "numeric"
cleaned_joined_mort_rr_data_long$pm_level <- as.numeric(cleaned_joined_mort_rr_data_long$pm_level)

#> Find the pm_level in the "cleaned_joined_mort_rr_data_long" dataset that is closest to "global_average_pm2.5" that is set up top in "lib_glob_parameters" chunk.

#> pm2.5 buckets, one of which will contain the global_avg_pm2.5. This bucket will be the one that is closest to the global average PM2.5 value that is set up top. In old STATA scripts, you will find that this process is carried out by a "rounding process". But, that has to be adjusted every year the dataset changes. What I have done below is agnostic to any data changes.

# figure out the unique PM2.5 values in the data and sort them in ascending order
unique_list_of_pm2.5_val_in_data <- sort(unique(cleaned_joined_mort_rr_data_long$pm_level))

# calculate how far the global average pm2.5 value is from each of the values in the above list of unique pm2.5 values
distance_from_global_avg_pm2.5 <- abs(unique_list_of_pm2.5_val_in_data - global_avg_pm2.5)

# *New assumption in here*: Which pm_level value in our current dataset is the closest to the "global_average_pm2.5"? If there are 2 such values, choose the one with a lower pollution number, so that our estimate is a conservation one (for now)
potential_pm2.5_buckets_indices <- which(distance_from_global_avg_pm2.5 == min(distance_from_global_avg_pm2.5))

# if there are more than one potential buckets in which the global_average_pm2.5 can land, this conditional statement below chooses the bucket with a lower pm2.5 level. This is a conservative step that we take for now and will reevaluate its implications.
if(length(potential_pm2.5_buckets_indices) < 2){
  global_avg_pm2.5_rounded <- unique_list_of_pm2.5_val_in_data[potential_pm2.5_buckets_indices]
} else {
  global_avg_pm2.5_rounded <- min(unique_list_of_pm2.5_val_in_data[potential_pm2.5_buckets_indices])
}

#> create a new temp columm that will be used to create yet another "rr_normalizer" column which will be used to create yet another "adjusted_mortality_rates" column. After generating the "rr_normalizer" column, the "temp" column will be dropped as it would have served its purpose by then. The "temp" column in the step below takes in the relative risk number of those rows where pm_level = "global_avg_pm2.5_rounded" number. In other words, it takes on those relative risk numbers that correspond to the current global average pm2.5 concentration level.  

# create a new "temp" column
cleaned_joined_mort_rr_data_long <- cleaned_joined_mort_rr_data_long %>%
  mutate(temp = ifelse(pm_level == global_avg_pm2.5_rounded, relative_risk, NA))

# group by cause, and age_interval and each row of each of these groups, gets the relative risk number that is equal to mean of "temp" column for that group. Capture this new information in a new column called "rr_normalizer".
cleaned_joined_mort_rr_data_long <- cleaned_joined_mort_rr_data_long %>%
  group_by(cause, age_interval_ll) %>%
  mutate(rr_normalizer = mean(temp, na.rm = TRUE)) %>%
  ungroup()

# drop the temp column
cleaned_joined_mort_rr_data_long <- cleaned_joined_mort_rr_data_long %>%
  select(-temp)

# add a new column called "adjusted mortality rate", which adjusts the mortality rate for a given age_cat, cause group, by their RR in relation to the RR at the rounded Global Average PM2.5. Here the assumption is that in the absence of the risk factor, age specific death rates would be proportionally lower. This dataset corresponds to the "file1" dataset in the STATA script. This is what "PM2.5 specific mortality rates" would be if PM2.5 = X. This helps us calcuate mortality rates for any given counterfactual PM2.5 value "X".

cleaned_joined_mort_rr_data_long <- cleaned_joined_mort_rr_data_long %>%
  mutate(adjusted_mortality_rate = (mortality_rate * relative_risk)/rr_normalizer)

#>---------------------------------------------------------------------------------------------->#



#>-----------------------Prep "all cause" mortality rates (loaded as a separate file up top) for "actual life table computation", adjusted to reflect higher (or lower) mortality rates at PM2.5 concentrations that are higher (or lower) than the global average.------------------------------------------------------------>#

# create a m_diff column, that takes the difference between "actual" and "adjusted" mortality rates
cleaned_joined_mort_rr_data_long <- cleaned_joined_mort_rr_data_long %>%
  mutate(m_diff = adjusted_mortality_rate - mortality_rate)

# * (New Assumption): summarise "cleaned_joined_mort_rr_data_long" dataset by summing up "m_diff", grouped by age_cat, pm_level and then sort by "pm_level" and "age_cat". Note that this m_diff_sum (which is calculated using the adjusted mortality rates concerning the 6 causes of deaths) will be used to adjust all cause mortality rates later on in the process. It should be noted that the "m_diff_sum" that we will add to the "all cause mortality" later on in the process, is an adjustment based on the 6 disease channels in question.

cleaned_joined_mort_rr_data_long_summary <- cleaned_joined_mort_rr_data_long %>%
  group_by(age_interval_ll, pm_level) %>%
  summarise(m_diff_sum = sum(m_diff, na.rm = TRUE)) %>%
  ungroup() %>%
  arrange(pm_level, age_interval_ll) 
  
# (* New Assumption) merging the summary dataset generated in the above step with "cleaned_gbd_mortality_rates_all_causes" dataset, using "age_interval" as the linking key. Then rename the "mortality_rate" column to "actual_mr". Note that the "all_causes" dataset does not have a "pm_level" column. So, each age_category in the joined dataset, has an associated set of 21 pm_levels, but for all of those the mortality_rate remains the same (that is an assumption that we make). We then adjust these mortality rates, by adding in the "m_diff_sum" column to the "actual_mr" column (which is the new name of the "mortality_rate" column), the output of which is assigned to the column named "nMx".

cleaned_joined_mort_rr_data_long_summary <- cleaned_joined_mort_rr_data_long_summary %>%
  left_join(cleaned_gbd_mortality_rates_all_causes_only, by = "age_interval_ll") %>%
  arrange(age_interval_ll, pm_level) %>%
  rename(actual_mr = mortality_rate)

# add a new nMx column, which is created by adding the "m_diff_sum" adjustment to the all cause mortality rates. But, note that "m_diff_sum" was calculated from only 6 PM2.5 specific disease channels. This is what "all cause mortality" rates would be if PM2.5 = X (where "X" is a counterfactual concentration)
cleaned_joined_mort_rr_data_long_summary <- cleaned_joined_mort_rr_data_long_summary %>%
  mutate(nmx = actual_mr + m_diff_sum)

# replace nMx with nmx/100000 (this column represents the "Mortality rate (deaths per person-year), adjusted"): This dataset corresponds to the "file2" dataset in Ken's STATA script. nMx is the mortality incidence rate for age interval between ages x and x + n, expressed in the units of deaths per person-year
cleaned_joined_mort_rr_data_long_summary <- cleaned_joined_mort_rr_data_long_summary %>%
  mutate(nmx = nmx/100000)



#>----------------------------------------------------------------------------------------------------------->#


#> Prepare age-specific mortalities attributed to PM2.5 (for cause-deleted)------------------------------------------>#

# Note that "cleaned_joined_mort_rr_data_long" corresponds to the "file1" tempfile in the STATA scripts. Adding 2 new columns called paf (Population Attributable Fraction) and pm_mortal_rate
cleaned_joined_mort_rr_data_long <- cleaned_joined_mort_rr_data_long %>%
  mutate(paf = 1 - (1/relative_risk), 
         pm_mortality_rate = paf * adjusted_mortality_rate)

# summary for cause-deleted life table (cdlt): This is the sum of total number of deaths across all 6 causes of death (corresponds to collapse statement that we see in part "f" of the STATA script).
cleaned_joined_mort_rr_data_long_summary_cdlt <- cleaned_joined_mort_rr_data_long %>%
  group_by(age_interval, age_interval_ll, age_interval_ul, age_gap, pm_level) %>%
  summarise(pm_mortality_rate = sum(pm_mortality_rate, na.rm = TRUE)) %>%
  ungroup()

# rename pm_mortality_rate to pm_nmx and then converting pm_nmx into a rate by dividing by 100000. The resulting dataset corresponds to "file-3" in the STATA script
cleaned_joined_mort_rr_data_long_summary_cdlt <- cleaned_joined_mort_rr_data_long_summary_cdlt %>%
  rename(pm_nmx = pm_mortality_rate) %>%
  mutate(pm_nmx = pm_nmx/100000)


#>--------------------------------------------------------------------------------------------------------------------------->#


#> Calcualte "Actual" Global Life Table, for various PM2.5 levels (corresponding to start of Part-2 in the STATA script)--------------->#

# Use "adjusted" all cause mortality rates, to compute actual life expectancy at birth in a world where PM2.5 = x (following a combination of Apte's 2018 paper supplemental information doc and Arias 2013 paper, which follow same terminology).

# define alpha_x to be 0.5 for every age group (as in Apte et al.). alpha represents the fraction of the age interval duration that the average dying cohort member survives. Given this alpha_x = 0.5, tells us that we assume deaths take place at the midpoint of each age interval. Note that the dataset we use below is the same one that we prepped above, i.e. "cleaned_joined_mort_rr_data_long_summary", i.e. file 2 in the corresponding STATA script.

cleaned_joined_mort_rr_data_long_summary <- cleaned_joined_mort_rr_data_long_summary %>%
  mutate(alpha_x = 0.5)

# compute nqx (its the probability of death during the age interval of duration n years i.e.between age x and age x+n)
# nqx = ndx/lx (equation 3, Arias, et al, 2013 & also Eq.3 of Apte's 2018 supplemental information doc). ndx represents the number of life table cohort deaths in a given age interval (x, x+n), from a given cause.

cleaned_joined_mort_rr_data_long_summary <- cleaned_joined_mort_rr_data_long_summary %>%
mutate(nqx = (nmx*age_gap)/(1 + ((1 - alpha_x)*(nmx)*(age_gap))))

# (* Assumption): set nqx = 1, if age_cat = max(age_cat), which as of now is "95+" and sorting by pm_level and age_interval
cleaned_joined_mort_rr_data_long_summary <- cleaned_joined_mort_rr_data_long_summary %>%
  mutate(nqx = ifelse(age_interval == "95+", 1, nqx)) %>%
  arrange(pm_level, age_interval_ll)

#> Compute lx (Population of cohort still alive at the beginning of the age interval). 

# lx is the survivor function. It considers the surviving population of a hypothetical birth cohort of 100000 individuals at age x. See equation 2 in Apte et al, 2018 (supplemental information doc). In other words, population of the lifetable cohort that is still alive at the beginning of age interval x depends on the number of individuals that are alive at the outset of the previous age interval x-l, and the fraction of members who survived that preceding age interval, (1 - nq(x-1)). For the first age interval (0-1), lx = 100000, because the everyone is alive at the beginning of the first age interval. For every interval, after the first one, we use the formula in equation 3 of the apte paper to calculate lx.

cleaned_joined_mort_rr_data_long_summary <- cleaned_joined_mort_rr_data_long_summary %>%
  mutate(lx = 100000) %>%
  group_by(pm_level) %>%
  mutate(temp_grp_wise_row_number = dplyr::row_number()) %>%  # adding this column so that we can avoid writing a loop to calculate lx in the next mutate statement
  mutate(lx = ifelse(age_interval != "0-1", (lx[temp_grp_wise_row_number -1] * (1 - nqx[temp_grp_wise_row_number - 1])), 100000)) %>%
  ungroup()

#> Compute ndx i.e. the life table cohort deaths in the given  age interval and nlx, i.e. life years lived by the cohort in the given age interval
cleaned_joined_mort_rr_data_long_summary <- cleaned_joined_mort_rr_data_long_summary %>%
  mutate(ndx = lx * nqx,
         nlx = ndx/nmx)

#> Compute nfx (which is a preparation for calculating the global "cause deleted" life table, that will be calculated after we are done with the "actual life table" calculation.
cleaned_joined_mort_rr_data_long_summary <- cleaned_joined_mort_rr_data_long_summary %>%
  arrange(pm_level, age_interval_ll) %>%
  mutate(nfx = 0) %>%
  group_by(pm_level) %>%
  mutate(nfx = (((age_gap[temp_grp_wise_row_number])*(lx[temp_grp_wise_row_number])) - nlx[temp_grp_wise_row_number])/(lx[temp_grp_wise_row_number] - lx[temp_grp_wise_row_number + 1])) %>%
  ungroup()

#> compute ntx 

# for age_interval_category == max(age_interval_category), set ntx = nlx
cleaned_joined_mort_rr_data_long_summary <- cleaned_joined_mort_rr_data_long_summary %>%
  mutate(ntx = NA,
    ntx = ifelse(age_interval_category == max(age_interval_category), nlx, ntx))

# for the rest, for each pm_level (group by pm_level) -> update ntx, by starting from max(age_interval_category) - 1 (which in our case will be the 90-94 age interval) and then, go back till the first interval. This means that for a given pm_level group, we would start at the bottom of the group and then go up. 

# number of unique age catgories
num_unique_age_cat <- max(cleaned_joined_mort_rr_data_long_summary$age_interval_category)

# number of unique pm levels (= nrow(cleaned_joined_mort_rr_data_long_summary)/num_unique_age_cat)
num_unique_pm_levels <- length(unique(cleaned_joined_mort_rr_data_long_summary$pm_level))


# Each pm level corresponds to 21 age categories and in total there are 18 unique pm levels. To calculate ntx, we use a nested for loop. The first for loop goes through each pm level and for each pm level we go through all age categories (except the max(age_interval_lower, i.e. 95+, for which we have already assigned a value above), but we start from the last age category - 1, i.e. the age category that is one below the max age category (for which we already have a value for ntx). Note that this happens for each pm level, which is why this process repeats 18 times as, 18 is the number of unique pm levels we have in our current dataset. All of this is done so that the following formula for ntx can be implemented in code: ntx = nlx[_n] + ntx[_n+1].

for(i in 1:num_unique_pm_levels){
  if(i == 1){
     temp_grp <- cleaned_joined_mort_rr_data_long_summary[1 : num_unique_age_cat, ]
  } else {
    temp_grp <- cleaned_joined_mort_rr_data_long_summary[((((i - 1)*(num_unique_age_cat)) + 1) :(i * num_unique_age_cat)), ]
  }
   temp_grp <- temp_grp %>%
      select(ntx, nlx)
  print(str_c("Iteration number", i, sep = "-"))
  for(j in (num_unique_age_cat - 1): 1){
  temp_grp$ntx[j] <- temp_grp$nlx[j] + temp_grp$ntx[j+1]
  }
  if(i == 1){
     cleaned_joined_mort_rr_data_long_summary$ntx[1:num_unique_age_cat] <- temp_grp$ntx
  } else {
    cleaned_joined_mort_rr_data_long_summary$ntx[((((i - 1)*(num_unique_age_cat)) + 1) :(i * num_unique_age_cat))] <- temp_grp$ntx
  }

}

#> Compute ex and then roud it to the nearest 1/1000000 
cleaned_joined_mort_rr_data_long_summary <- cleaned_joined_mort_rr_data_long_summary %>%
  mutate(ex = ntx/lx, 
         ex = plyr::round_any(ex, 0.000001))


#> Compute life expectancy at birth 
actual_life_ex_birth <- cleaned_joined_mort_rr_data_long_summary %>%
  filter(age_interval_ll == 0, pm_level == global_avg_pm2.5_rounded) %>%
  summarise(avg_life_exp_at_birth = mean(ex))

#> At this stage create a copy of the cleaned_joined_mort_rr_data_long_summary and name it the "actual_table"
actual_life_table <- cleaned_joined_mort_rr_data_long_summary


#>------------------------------------------------------------------------------------------------------->#


#> ------------------Calculate "cause deleted" global life table, for various causes------------------------------------------->#


#>  We start of with the "cleaned_joined_mort_rr_data_long_summary_cdlt" data that we created above (one that corresponds to file-3 tempfile in the corresponding STATA script).

cleaned_joined_mort_rr_data_long_summary_cdlt

#> Part 1: Follow Apte et al and Arias et al procedure to derive the counterfactual probability of death after eliminating PM2.5 as a possible cause of death

# For this cause-deleted part of the script, we calculate similar variable as we did for the "actual_life_table" (which was generated using "all causes" data, which to be clear oes not mean sum of 6 disease channels, but rather the actual "all causes" category of data that we download from the GBD) part of the script, but assuming that the death by pm2.5 (occuring via the sum of the 6 disease channels) is eliminated. Given that assumption we calculate a new life table, which we name as the "cause eliminated" life table (because we have eliminated PM2.5 as a cause of death, by summing up the 6 causes mortality data, converted it into life expectancy numbers and then subtracted it from the actual life table). Given this, how does the life expectancy at different age intervals changes and how does that compare to the actual life table? This is the question that we finally answer by taking a difference between the actual table and the cause-eliminated table. 


# The following computation is based on Apte et al, 2018 and Arias et al 2013 papers. The terminology is a mix of both so, refer both papers. Although Arias paper explains the underlying concepts in a much more clear fashion.

# Add a alpha_x column to the "cleaned_joined_mort_rr_data_long_summary_cdlt" dataset
cleaned_joined_mort_rr_data_long_summary_cdlt <- cleaned_joined_mort_rr_data_long_summary_cdlt %>%
  mutate(alpha_x = 0.5)

# create a new "nqx_attrib" column (See Apte's paper supplemental information section): This is the age specific death rate, attributable to PM2.5
cleaned_joined_mort_rr_data_long_summary_cdlt <- cleaned_joined_mort_rr_data_long_summary_cdlt %>%
  mutate(nqx_attrib = (pm_nmx * age_gap)/(1 + ((1 - alpha_x)*(pm_nmx)*(age_gap))))

# Join the above table with the "actual table" calculated in the section above.
cleaned_joined_mort_rr_data_long_summary_cdlt <- cleaned_joined_mort_rr_data_long_summary_cdlt %>%
  left_join(actual_life_table, by = c("age_interval", "age_interval_ll", "age_interval_ul", "age_gap", "alpha_x", "pm_level"))

#  Compute nqx_deleted using nrx and nqx. nrx = nqx_attrib/nqx in Apte et al (2018) supplemental information section. This is equivalent to pm_nmx/nmx in Arias et al (Equation 6). 

cleaned_joined_mort_rr_data_long_summary_cdlt <- cleaned_joined_mort_rr_data_long_summary_cdlt %>%
  mutate(nrx = pm_nmx/nmx, 
         nqx_del = 1 - ((1 - nqx)^(1 - nrx)))

#> Part-2: Calculate cause deleted life expectancy
 
# Compute lx_del, which is the cause deleted population of cohort still alive at the beginning of age interval and sort by pm_level, age_interval_ll
cleaned_joined_mort_rr_data_long_summary_cdlt <- cleaned_joined_mort_rr_data_long_summary_cdlt %>%
  mutate(lx_del = NA) %>%
  arrange(pm_level, age_interval_ll)

# Compute "lx_del" (which is the cause-deleted version of lx, which we calculated in the actual life table)
cleaned_joined_mort_rr_data_long_summary_cdlt <- cleaned_joined_mort_rr_data_long_summary_cdlt %>%
   mutate(lx_del = 100000) %>%
  group_by(pm_level) %>%
  mutate(lx_del = ifelse(age_interval != "0-1", (lx_del[temp_grp_wise_row_number - 1] * (1 - nqx_del[temp_grp_wise_row_number - 1])), 100000)) %>%
  ungroup()


# Compute "nlx_del" (which is the corresponding version of nlx, which we calculated in the actual life table) using nfx from "actual life table"
cleaned_joined_mort_rr_data_long_summary_cdlt <- cleaned_joined_mort_rr_data_long_summary_cdlt %>%
  mutate(nlx_del = NA) %>%
  group_by(pm_level) %>%
  mutate(nlx_del = ((age_gap[temp_grp_wise_row_number] - nfx[temp_grp_wise_row_number]) * (lx_del[temp_grp_wise_row_number])) + (nfx[temp_grp_wise_row_number] * lx[temp_grp_wise_row_number + 1])) %>%
  ungroup()


#> Compute tx_del

cleaned_joined_mort_rr_data_long_summary_cdlt <- cleaned_joined_mort_rr_data_long_summary_cdlt %>%
  mutate(tx_del = NA,
         temp_row_num = row_number(),
         tx_del = ifelse(age_interval == "95+", (ex[temp_row_num]*lx_del[temp_row_num])/(1 - nrx[temp_row_num]), NA))

# Each pm level corresponds to 21 age categories and in total there are 18 unique pm levels. To calculate tx_del, we use a nested for loop. The first for loop goes through each pm level and for each pm level we go through all age categories (except the max(age_interval_lower, i.e. 95+, for which we have already assigned a value above), but we start from the "last age category - 1", i.e. the age category that is one below the max age category (for which we already have a value for tx_del). Note that this happens for each pm level, which is why this process repeats 18 times as, 18 is the number of unique pm levels we have in our current dataset. All of this is done so that the following formula for tx_del can be implemented in code: tx_del[current_grp_wise_row_number + 1] + nlx_del[current_grp_wise_row_number] 

for(i in 1:num_unique_pm_levels){
  if(i == 1){
     temp_grp <- cleaned_joined_mort_rr_data_long_summary_cdlt[1 : num_unique_age_cat, ]
  } else {
    temp_grp <- cleaned_joined_mort_rr_data_long_summary_cdlt[((((i - 1)*(num_unique_age_cat)) + 1) : (i * num_unique_age_cat)), ]
  }
   temp_grp <- temp_grp %>%
      select(ex, lx_del, nrx, tx_del, nlx_del) %>%
  print(str_c("Iteration number", i, sep = "-"))
  for(j in (num_unique_age_cat - 1): 1){
  temp_grp$tx_del[j] <- temp_grp$nlx_del[j] + temp_grp$tx_del[j+1]
  }
  if(i == 1){
     cleaned_joined_mort_rr_data_long_summary_cdlt$tx_del[1:num_unique_age_cat] <- temp_grp$tx_del
  } else {
    cleaned_joined_mort_rr_data_long_summary_cdlt$tx_del[((((i - 1)*(num_unique_age_cat)) + 1) :(i * num_unique_age_cat))] <- temp_grp$tx_del
  }

}

#> Compute counterfactual life expectancy at any given age interval "x"

cleaned_joined_mort_rr_data_long_summary_cdlt <- cleaned_joined_mort_rr_data_long_summary_cdlt %>%
  mutate(counterfactual_life_exp = tx_del/lx_del,
         counterfactual_life_exp = plyr::round_any(counterfactual_life_exp, 0.000001))

#> 
```

